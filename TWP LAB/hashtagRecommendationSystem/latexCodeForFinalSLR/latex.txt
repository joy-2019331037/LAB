\documentclass[25pt]{article}
\usepackage{graphicx} % Required for inserting images
\usepackage{geometry}
\usepackage[english,spanish]{babel}
\usepackage{blindtext}
\usepackage{lipsum}
\usepackage{parskip}
\usepackage{setspace}
\usepackage{caption}
\usepackage{multicol}
\usepackage{hyperref}
\usepackage{float}
\usepackage{changepage}
\usepackage{longtable}
\usepackage{multirow}
\usepackage{ragged2e}
\usepackage{subfigure}
\usepackage[style=apa,backend=biber]{biblatex}


\usepackage{parskip}

\usepackage{tikz}

\usetikzlibrary{shapes, arrows}
\usetikzlibrary{shapes.geometric}
\usetikzlibrary{positioning}
\usetikzlibrary{positioning, arrows.meta}
\usetikzlibrary{shapes, arrows.meta}

\tikzstyle{block} = [rectangle, draw, fill=blue!20, text width=6em, text centered, rounded corners, minimum height=3em]
\tikzstyle{line} = [draw, -latex']
\tikzstyle{cloud} = [draw, ellipse, fill=red!20, node distance=3cm, minimum height=2em]

\usepackage{schemata}
\usetikzlibrary{mindmap}

\usetikzlibrary{fit,positioning}

\geometry{
    top=2.5cm,
    left=2.8cm,
    right=2.8cm,
    bottom=2.44cm
}

\tikzset{
every picture/.append style={
  execute at begin picture={\deactivatequoting},
  execute at end picture={\activatequoting}
  }
}

\usepackage{titlesec}

\titleformat{\section}{\fontsize{10}{12}\selectfont\bfseries\centering}{\thesection. }{1em}{}
\titlespacing*{\section}{0pt}{\baselineskip}{\baselineskip}

\titleformat{\subsection}{\fontsize{10}{12}\selectfont \itshape}{\thesubsection. }{1em}{}
\titlespacing*{\subsection}{0pt}{\baselineskip}{\baselineskip}

\titleformat{\subsubsection}{\fontsize{10}{12}\selectfont \itshape}{\thesubsubsection. }{1em}{}
\titlespacing*{\subsubsection}{0pt}{\baselineskip}{\baselineskip}

\usepackage[pages=all]{background}

\backgroundsetup{
 scale=1, %escala de la imagen, es recomendable que sea del mismo tamaño que el pdf
 color=black, %fondo a usar para transparencia
 opacity=0.2, %nivel de transparencia
 angle=0, %en caso de querer una rotación
     contents={%
  \includegraphics[width=\paperwidth,height=\paperheight]{format.pdf} 
 }%
}

\usepackage{fontspec}
\setmainfont{Times New Roman}

\title{\vspace{0cm} \fontsize{12}{12}\selectfont \textbf{CREATING EFFICIENT AND RESOURCE-CONSCIOUS IMAGE-BASED HASHTAG RECOMMENDATIONS WITH THE HELP OF MACHINE LEARNING} 
}
\author{\fontsize{10}{12}\selectfont \textbf{\fontsize{10}{12}\selectfont Pulok Saha,} \\ \textbf{\fontsize{10}{12}\selectfont Sourav Bhowmik Joy}\\ \\
\small{\textbf{\fontsize{10}{12}\selectfont Computer Science \& Technology}}\\
\small{\fontsize{10}{12}\selectfont \textbf{Shahjalal University of Science \&  Techonlogy, Sylhet}} \\ \small{\fontsize{10}{12}\selectfont Tel.: 01311338931, 01521771459}\\
\small{\fontsize{10}{12}\selectfont E-mail: \{sourav35joy80, puloksaha.ayon\}@gmail.com}
}
\date{\vspace{-6mm}}

\begin{document}

\fontsize{10}{12}\selectfont

\selectlanguage{spanish}

\def\tablename{Tabla}%

\setlength{\parskip}{0mm}

\maketitle

\setlength{\parskip}{3mm}

\selectlanguage{english}

\renewcommand\abstractname{}

\begin{figure}
    \centering
    \includegraphics[width=10cm]{figures/fig1.png}
    \caption{Hashtag recommendations matching with corresponding text.}
    \label{fig:enter-label}
\end{figure}

\begin{abstract}
    \fontsize{10}{12}\selectfont
    \textbf{Abstract:} Hashtag-based image descriptions are a popular approach for labeling images on social media platforms. This systemic Literature Review provides an insight into the system of recommending image-based hashtags. A total of 15 articles were studied all of which contributed to the generation the literature review that follows. On social media platforms, content can be traced using hashtags, therefore making hashtags like a key-pair value in a dictionary. Hashtags are generated by users and different users might come up with different tags for similar posts, due to their different preference and/or community effect. Therefore, it is highly desirable to characterize the users’ tagging habits.
    Machine learning helps in making this method easier. Machine learning is a method of finding patterns in the data, and using it, researchers tend to find and predict relevant hashtags for images in order. In this review we are exploring the possible better solutions through various approaches and expect this study to accelerate the advancement of hashtag recommendation.

    \vspace{3mm}
    
    \textbf{Keywords:} Hashtag, Images, Machine Learning, Prediction.
    \vspace{-7mm}
\end{abstract}


\vspace{1cm}

\setlength{\columnsep}{1cm}

\renewcommand{\tablename}{Tabla}

\begin{multicols}{2}
\fontsize{10}{12}\selectfont

\section{INTRODUCTION}


In the ever-evolving landscape of social media, the use of hashtags has become a ubiquitous means of content categorization and user engagement. Hashtags, denoted by the symbol "\#" preceding single words, concatenations, or abbreviations, accompany online images, particularly on platforms like Instagram and Pinterest. These tags serve diverse purposes, ranging from succinctly summarizing the content of a user's post to capturing the attention of followers. For instance, while simple hashtags like \textit{\#cat} and \textit{\#hill} describe basic objects or locations in a photograph, emotional ones like \textit{\#love} convey the user's feelings, and thematic or inferable hashtags such as \textit{\#itsfashion} and \textit{\#autumn} categorize content or provide contextual information .

Modern techniques for content understanding leverage machine learning algorithms, with deep learning methods like convolutional networks gaining popularity for their impressive performance. However, training these models traditionally relies on extensive sets of manually annotated data, presenting challenges in terms of time and resources. Moreover, such datasets may overlook crucial aspects of image interpretation, such as sentiment, user-centric information, and the dynamic nature of online data distribution.

This paper explores an innovative approach by considering the vast amount of image content online where users have voluntarily associated hashtags. This alternative training data source offers significant advantages, generating large labeled datasets more efficiently than manual annotation and capturing authentic user interests. The focus is on predicting hashtags for images uploaded by specific users, incorporating both image pixel representations and user metadata in the learning process.


Recognizing the extensive variety of classes within images, the paper addresses the challenge of efficiently collecting and annotating data for each class. It proposes algorithms that mimic human cognitive processes, allowing the model to identify objects even when encountering them for the first time. This approach involves extracting information about an object from alternative sources and utilizing it to facilitate identification.

The importance of hashtag usage extends beyond individual expressions to shape trends and influence social media dynamics. While large companies may allocate considerable resources to identify and leverage popular hashtags, small businesses and individual content creators face limitations in adopting similar strategies. This underscores the need for an automated tool capable of analyzing content, suggesting relevant hashtags based on context, and providing a metric for their potential impact on social media.

As we delve into the literature on this subject, it becomes apparent that understanding hashtag dynamics is crucial for effective content dissemination. The following systematic literature review (SLR) aims to comprehensively explore existing research on creating efficient and resource-conscious image-based hashtag recommendations using machine learning. By synthesizing insights from multiple papers, we seek to identify trends, gaps, and potential future directions in this evolving field.

The subsequent part of this paper is structured as follows. Section 2 outlines the methodology employed in this study. The outcomes and discoveries of the research are deliberated in Section 5. Other sections outline related works that have already been completed on this topic and potential avenues for future research endeavors while the review is brought to a conclusion in Section 6.

\section{STUDY METHODOLOGY}

A literature review aims to provide a comprehensive and unbiased overview of the existing literature focusing on a specific research topic, intended to researchers and practitioners. This document is generated based on several key factors outlined below -

\subsection{\textbf{Search Strategy}}
Developing a comprehensive search strategy is crucial for identifying relevant literature for a systematic literature review (SLR). Following are some of the important points highlighting the strategies for searching related article and journals - 
\subsubsection{Identifying key concepts}
 Everywhere in the literature review, similar search terms were utilized and combined so that a better understanding of the study materials could be attained. 

\subsubsection{Source of information}
Relevant databases for the study of this hashtag recommendation topic was searched out most of which are mentioned below -
\begin{itemize}
\item Scopus
\item Google Scholar 
\item IEEE Explorer
\item ACM Digital Library
\item ScienceDirect
\end{itemize}


\subsubsection{Refined Searching}
Database specific advanced search features were adopted to refine and narrow down the searching scope.

Examples include filters for publication date, document type and keywords.

\subsubsection{Hand Searching Key Journals}
Relevant journals and conference proceedings related to this field were hand searched to get additinal articles.

\subsubsection{Citation Tracking}
 Proper citation tracking was ensured to identify seminal papers and other relevant literature.

\subsubsection{Iterative Process}
\begin{itemize}
    \item Relevance of retrieved articles were evaluated based on the initial search.
    \item Search terms based on the initial results were refined and accordingly received feedback was evaluated.
\end{itemize}

\vspace{1 cm}
To be more specific and relevant to the study objective, the search procedure was only applied to the
journals, book chapters, and conferences published over
the last 10 years since social media  did not exit at large scale before this timeline and neither did the precious image-based hashtags.

\subsection{\textbf{Inclusion \& Exclusion Criteria  for articles}}

\subsubsection{Inclusion Criteria}
\begin{itemize}
    \item{\textbf{ Relevance to Image-Based Hashtag Recommendation :}}
     Papers specifically addressing the topic of image-based hashtag recommendations were prioritized.
     \item {\textbf{Machine Learning Approaches :}}
     Articles employed with machine learning methodologies, such as deep learning or other relevant algorithms, for the development or enhancement of any type of hashtag recommendation systems were taken into consideration.

     \item{\textbf{Publication Type : }}
      Peer-reviewed journal articles, conference papers, and academic publications was considered important as they provide rigorous and scholarly research.

      \item{\textbf{Diversity of Approaches :}}
      Studies utilizing a diverse range of machine learning techniques, including but not limited to convolutional networks, recurrent neural networks, and ensemble methods, was considered to provide a comprehensive overview.

      \item{\textbf{Application Domains :}}
      Contents (especially images) from various application domains, such as social media platforms, e-commerce, or multimedia content sharing, was included to capture the breadth of image-based hashtag recommendation implementations.

\end{itemize}


\subsubsection{Exclusion Criteria }

\begin{itemize}
    \item {\textbf{Irrelevant Topics   :}}
    Papers that do not specifically focus on image-based hashtag recommendations or do not leverage machine learning techniques for this purpose were not taken into consideration.
    \item{\textbf{Insufficient Methodological Detail  :}}
     Studies lacking clear descriptions of the machine learning methodologies employed or those with inadequate information on the image-based hashtag recommendation process were easily excluded.
     \item{\textbf{Outdated Publications    :}}
      Papers published more than ten years ago were excluded to prioritize recent advancements and methodologies in the rapidly evolving field of machine learning for image-based hashtag recommendations.
      \item{\textbf{Non-Academic Sources    :}}
      Non-peer-reviewed sources, such as blog posts, news articles, and non-academic websites, were excluded to maintain the academic rigor of the literature review.
\end{itemize}

By applying these inclusion and exclusion criteria, this systematic literature review attempted to ensure the selection of relevant, high-quality research papers that contribute significantly to the understanding of image-based hashtag recommendations system with the aid of machine learning.

\section{RELATED WORK}

In this section, we delve into the existing research landscape on hashtag recommendation, exploring various methodologies and approaches, particularly those centered around content-based recommendations and personalized recommendations.

\subsection{\textbf{Content-Based Hashtag Recommendations}}
\begin{itemize}
    \item Traditional methods analyze users' tagging behaviors, with recent advancements incorporating Convolutional Neural Networks (CNNs) to learn image semantics.
    \item Notable approaches include using features from existing CNNs or building end-to-end models for collective learning of image and tag semantics [Wei et al. 2014, Gong et al. 2013, Gong et al. 2014, Wang et al. 2016].
\end{itemize}

\subsection{\textbf{Personalized Hashtag Recommendations}}
Distinguish personalized hashtag recommendations, considering users' historical tagging behaviors to implicitly model their preferences.
Methods include constructing tag vocabularies, edge prediction in heterogeneous networks, and tensor factorization on user-item-tag tensors [Qian et al. 2013, Guan et al. 2009, Feng and Wang 2012, Rendle and Schmidt-Thieme 2010, Fang et al. 2015, Nguyen et al. 2017].

\subsection{\textbf{Additional Perspectives from Specific Papers}}
\begin{itemize}
    \item \subsubsection{Harrison Dataset}
    Introduces the Harrison dataset for hashtag prediction, emphasizing the need for a benchmark to accelerate hashtag recommendation. The dataset includes 57,383 images from Instagram, each with an average of 4.5 related hashtags.
    \item \subsubsection{Zero-Shot Classification}
    Addresses Zero-Shot Classification and Generalized Zero-Shot Classification, using a restrictive generator to create artificial training models. The study includes comparisons with generative models across various datasets.
    \item \subsubsection{Supervised Machine Learning Algorithms}
    Analyzes the effectiveness of supervised machine learning algorithms concerning precision, learning rate, complexity, and overfitting risks. Provides a general comparison with state-of-the-art machine learning algorithms across different application areas.
    \item \subsubsection{User Conditional Hashtag Prediction for Images}
    Explores user metadata, such as age and gender, in conjunction with image features from Convolutional Neural Networks (CNNs) for hashtag prediction. The method leverages user-defined context information [8].
\end{itemize}

\vspace{1cm}
This overview highlights the breadth and depth of research in the field, covering various aspects of content-based and personalized hashtag recommendations. The literature review serves as a foundation for understanding existing methodologies, gaps in research, and potential avenues for further exploration in the quest to create efficient and resource-conscious image-based hashtag recommendations through machine learning.

\section{DATA EXTRACTION \& ANALYSIS}

\subsection{Data Collection}

\begin{itemize}
    \item\textbf{Source \& Categories   :}
    Images were collected from various social media platforms using Instaloader. Ten distinct classes were defined based on popular topics found on Instagram, including animals, art, fashion, fitness, flowers, food, instagood, nature, selfie, and sports.
    \item\textbf{Quantity and Quality Assurance :}
    Papers made various approaches for collecting quality images of different. However each class consisted of around 800 images, ensuring a diverse and representative dataset. A robust data collection method was employed to guarantee accurate and well-described statistics, forming the foundation for subsequent decisions.
\end{itemize}

\subsection{Data Cleaning}

\begin{itemize}
    \item\textbf{Noise Reduction :} 
    After data collection, a meticulous cleaning process was undertaken to eliminate unnecessary or noisy data. Each class was scrutinized, and unwanted data that wasn't properly categorized was identified and removed.

\item\textbf{Consistency    :} 
Ensured consistency with other datasets by addressing inconsistencies arising from user input errors, corrupted data, and variations in data definitions across sources. Data cleaning was tailored to fit the unique characteristics of each dataset.

\item\textbf{Outlier Identification  :}
Utilized transfer learning as a classification method, focusing on identifying noisy images by measuring their distance from centroids. Images exceeding a defined threshold (two standard deviations from the mean) were considered noisy and subsequently removed.
\end{itemize}



\subsection{Data Processing}
Several papers employed various methodology and Machine Learning algorithms to process the collected data in order to find out a pattern from the models using vivid datasets. Some of the most used methods are discussed below -

\vspace{0.5cm}
\begin{itemize}

\item\textbf{Transfer Learning with VGG-19   :} 
Processed cleaned data using transfer learning with VGG-19, a convolutional neural network (CNN) algorithm renowned for its efficacy in various computational tasks. VGG-19 automatically analyzes spatial hierarchies of features through backpropagation, employing convolutional layers, fully connected layers, and pooling layers.

\item\textbf{Data Classification    :} 
VGG-19, a dominant class in deep neural networks, was employed for image classification. It is widely used in image recognition tasks such as image classification, object detection, and face recognition. Transfer learning facilitated the classification of images into predefined classes.

\item\textbf{Extension to CNN   :}
Extended the CNN methodology, incorporating transfer learning to train data classes effectively. This approach is particularly useful for classifying problems and regression problems in image recognition, leveraging nearest training sets in the feature space.

\item\textbf{Supervised Learning :}
Employed a supervised learning method to train the collected data. The training model categorized images into classes based on associated hashtags. The model included parameters such as epoch, batch size, and learning rate.



\end{itemize}





\section{Data Analysis \& Result}
Almost all of the studied papers and journals trained a model based on the collected data which is capable of suggesting hashtags based on images. However there were varities in the methods obtained for displaying the outputs described by respective papers for the users. Some of the common output presentation processes are discussed below -

\vspace{0.5cm}

\begin{itemize}
    \item\textbf{ Transfer Learning with TensorFlow.js and HTML Integration :}
    For hashtag prediction, some papers implemented Transfer Learning using TensorFlow.js and HTML for seamless integration with the frontend to showcase the results. The process began with the acquisition of images from Instagram using Instaloader, resulting in a dataset of around 5000 images. 
    
    Subsequently, the images were preprocessed, leading to ten classes with approximately 700 images in each. Transfer learning was chosen for training due to its compatibility with limited datasets and demonstrated efficiency. The trained model was then converted into TensorFlow.js, allowing it to be loaded onto the webpage alongside HTML and CSS. 
    
    The final framework incorporated small batches of transfer learning for training and testing, enabling the prediction of hashtags for various images. Users could upload an image on the website's homepage, and upon clicking "predict," hashtags were fetched and accurately predicted, with the output displayed on the webpage.

    \begin{figure}[H]
    \centering
    \includegraphics[width=1\linewidth]{figures/fig2.png}
    \caption{Figure showing the predicted hashtags for the uploaded image}
    \label{fig:enter-label}
    \end{figure}

    \item\textbf{Comparative Effectiveness Analysis :}
    Several papers opted for a comparative analysis of the proposed method against existing approaches. Precision, recall, and F1-score were the evaluation metrics, plotted against the number of hashtags returned by recommendation methods. The proposed MACON method exhibited significant improvements across all three metrics compared to competitors. Notably, when compared with the best competitor CoA, MACON achieved absolute improvements ranging from 12.8\% to 23.6\% in precision, 8.6\% to 20.8\% in recall, and 10.7\% to 13.4\% in F1-score. The analysis included a comparison with various methods, such as ImgAtt, T2W, TLSTM, and personalized FM-IC. Further, the study conducted a performance gain analysis by considering different components of the proposed method, emphasizing the importance of content modeling and user habit modeling for recommendation accuracy.

  

    \item\textbf{Performance Gain Analysis :}
The authors conducted a meticulous analysis of the proposed method, MACON, focusing on three crucial components: text input, image input, and user habit modeling. To highlight the significance of the user habit modeling module, they introduced variants of MACON, namely MACONt+i, MACONi+h, and MACONt+h, by selectively removing or retaining certain components.

Firstly, MACON exhibited superior performance compared to MACONt+i, emphasizing the critical role of the habit modeling module. The absolute improvements ranged from 9.3\% to 16.5\% in F1-score when the parameter K varied from 1 to 9. Notably, MACONt+i even outperformed CoA by up to 16.8\%, underlining the efficacy of the adopted parallel co-attention for services where both image and text contribute significantly to tagging.

Secondly, MACON outperformed both MACONt+h and MACONi+h across all metrics, indicating the collective utility of text and image inputs for hashtag recommendation. The average relative F1-score improvements over MACONt+h and MACONi+h ranged from 7.6% to 15.6%, emphasizing the substantial enhancement in recommendation accuracy achieved through hybrid modeling.

Thirdly, in comparison with the TLSTM method, MACONt+h demonstrated absolute improvements ranging from 10.8\% to 15.8\% in F1-score. This further affirmed the effectiveness and applicability of the proposed user habit modeling module, positioning it as a valuable addition to the field.


    \begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{figures/table.png}
     \captionsetup{justification=centering}
    \caption{The performance gain analysis. Both hybrid content modeling and user habit modeling are useful to improve recommendation accuracy.}
    \label{fig:enter-label}
    \end{figure}


\item\textbf{Parameter Sensitivity Study    :}The authors of the some papers delved into a parameter sensitivity study, focusing on the embedding size (d) and memory size (L) in their method, MACON. Their objective was to understand how these parameters influence recommendation accuracy.

For the embedding size (d), the authors varied it from 100 to 500, observing notable performance improvements as d increased. However, diminishing returns were noticed beyond a certain threshold, specifically from 400 to 500. Considering the trade-off between computational resources and performance gain, they opted for an embedding size of d = 300.

Regarding the memory size (L), representing the historical posts selected to model a user's tagging habit, variations from 1 to 5 showed relatively stable performance. Consequently, they fixed the memory size at L = 2 for their experiments.

 \begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{figures/fig3.png}
     \captionsetup{justification=centering}
    \caption{The parameter sensitivity study. The performance
of MACON increases as d increases, and stays relatively stable as L varies. We fix d = 300 and L = 2 in this work.}
    \label{fig:enter-label}
    \end{figure}


\item\textbf{Accuracy metrics for VGG-19 model  :}
Many of the articles that used VGG-19 as their fundamental model for predicting hashtag suggestions included various accuracy evaluation metrics namely, confusion matrix, loss function etc to measure the performance given by their respective models.

One of the articles published from International Journal of Engineering Research \& Technology (IJERT) listed their model accuracy parameters as such -

\subsection{Confusion Matrix for non-normalized VGG-19}
The confusion 
matrix for non-normalized VGG-19 prediction used in this paper has a 
definitely high accuracy that ranges to about 68\%, as seen from the graph below (fig. 5).
The loss observed has always been kept 
minimal to ensure accurate predictions.

 \begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{figures/fig4.png}
     \captionsetup{justification=centering}
    \caption{Figure showing the confusion matrix for non-normalized VGG-19.}
    \label{fig:enter-label}
    \end{figure}


\subsection{Confusion Matrix for normalized VGG-19}
The confusion matrix for normalized VGG-19 (fig. 
6) is quite similar to the non-normalized one with respect to 
accuracy and misclass and also matching true and predicted 
labels.
 \begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{figures/fig5.png}
    
    \caption{Figure showing the confusion matrix for normalized VGG-19.}
    \label{fig:enter-label}
    \end{figure}

\subsection{Loss Function}
The model's loss function was obtained using the train data and is shown in fig. 7. The model loss for test data has been limited to be as 
low as possible.
     \begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{figures/fig6.png}
    \caption{Figure showing the train and test curve for model loss using 
VGG-19.
}
    \label{fig:enter-label}
    \end{figure}


\subsection{Model Accuracy}
When final model accuracy was computed, it provided the following result as shown in fig. 8. The accuracy 
score has been maintained to be as high as possible upto 
68.14\%.
     \begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{figures/fig7.png}
     \captionsetup{justification=centering}
    \caption{Figure showing the train and test curve for model accuracy 
using VGG-19.}
    \label{fig:enter-label}
    \end{figure}


Thus it can be concluded that this particular paper and their chosen model was correct to a large scale in predicting appropriate hashtags from images. 
 
\end{itemize}


\section{Discussion}
This systematic literature review on hashtag recommendation combines insights from numerous journals and papers. Since this trend of posting/using hashtags on images on social media platforms is a very recent one, research interest in this particular sector has not yet caught attention of keen learners and graduates. There are only a few journals and papers available for rigorous study of this topic. However following is a discussion about some of the key findings that we obtained and the limitations of this literature review. 
\subsection{Key Findings}
Our study revealed that meticulous data collection and cleansing yield excellent results. Building an end-to-end image-based hashtag recommendation system using machine learning, including CNN, KNN, and transfer learning, was a valuable learning experience. However, deep learning methods may face challenges with data requirements. Future steps involve enhancing classification accuracy, particularly in fully supervised approaches. In this era of social media, image-based hashtag recommendations can go on to be a newer and interesting side of Machine Learning based research topic.
\subsection{Review Limitations }
While this review study endeavors to offer a comprehensive exploration of hashtag recommendation from images, certain limitations warrant acknowledgment. Primarily, the selection of the primary literature set adheres to specific search criteria outlined in the methodology section. However, this approach may inadvertently omit relevant papers that could contribute valuable insights. The possibility of enhancing the inclusivity of the review by employing alternative search methodologies remains an avenue for future investigations.

Moreover, the study acknowledges limitations in data extraction accuracy and potential misclassification during the implementation of the proposed models. A secondary review was conducted to mitigate these risks, underscoring the commitment to refining the quality of data and classifications. Despite these limitations, this study contributes valuable insights on hashtag recommendation system from images, paving the way for future research endeavors to address and overcome these challenges.


\section{References}
[1] 

Stéphane Herbin, Maxime Bucher, Frédéric Jurie. Zero-Shot
Classification by Generating Artificial Visual Features. RFIAP, Jun
2018, Paris, France.hal-01796440

[2] 

Paredesand Philip HS Torr - Bernardino Romera. An embarrassingly
simple approach to zero-shot learning. In ICML, pages 2152–2161,
2015.

[3] 

Shreyash Pandey, Abhijith Pathak. Predicting Instagram tags with and
without data.

[4] 

Stephane Herbin, Maxime Bucher, Frederic Jurie. Generating Visual
Representations for Zero – Shot Classification, arXiv:1708.06975v3
[cs.CV] 11 Dec 2017.

[5] 

Mohammad Norouzi et al. “Zero-shot learning by convex
combination of semantic embeddings”. In: arXiv preprint
arXiv:1312.5650 (2013).

[6] 

Ilya Sutskever, Geoffrey E Hinton, and Alex Krizhevsky. “ImageNet
Classification with Deep Convolutional Neural Networks”. In:
Advances in Neural Information Processing Systems Twenty-five.
Ed. by F. Pereira et al. Curran Associates, Inc., 2012, pp. 1097–1105.
url: http://papers.nips.cc/paper/ 4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf.
International Journal of Engineering Research \& Technology (IJERT)
http://www.ijert.org ISSN: 2278-0181
IJERTV9IS070419
(This work is licensed under a Creative Commons Attribution 4.0 International License.)
Published by :
www.ijert.org
Vol. 9 Issue 07, July-2020
1212

[7] 

Hanxiang Lee, Minseok Park, Junmo Kim. HARRISON: A
Benchmark on Hashtag Recommendation for Real-world Images in
Social Networks, arXiv:1605.05054v1 [cs.CV] 17 May 2016.

[8] 

Narina Thakur, Amanpreet Singh and Aakanksha Sharma. A Review
of Supervised Machine Learning Algorithms, 978-9-3805-4421-
2/16/\$31.00 c 2016 IEEE.

[9] 

Tomas Mikolov, Yoram Singer, Mohammad Norouzi, Andrea Frome,
Jonathon Shlens, Samy Bengio, Greg S. Corrado, Jeffrey Dean. ZeroShot Learning by Convex Combination of Semantic Embeddings.
arXiv:1312.5650v3 [cs.LG] Mar 2014.

[10] 

Jason Weston, Emily Denton, Manohar Paluri, Lubomir Bourdev, Rob
Fergus. User Conditional Hashtag Prediction for Images, 2015 ACM.
ISBN 978-1-4503-3664-2/15/08..\$15.00.DOI:
http://dx.doi.org/10.1145/2783258.2788576.

[11] 

O. Tsur, and A. Rappoport, “What’s in a Hashtag? A Content Based
Prediction of the Spread of Ideas in Microblogging Communities”. In:
Proceedings of the 5th ACM International Conference on Web Search
and Data Mining, 2012, pp. 643-652.

[12] 

Y.Y. Ahn, F. Menczer, and L. Weng, "Virality Prediction and
Community Structure in Social Networks", Scientific Reports, 2013,
3 (2522).

[13] 

Hanbury, A survey of methods for image annotation, J. Vis. Lang. 
Comput. 19 (5) (2008) 617–627.

[14] 

L. Fei-Fei, A. Karpathy, “Deep visual-semantic alignments for
generating image descriptions”, Proceedings of the IEEE Computer
Society Conference on Computer Vision and Pattern Recognition,
CVPR’15 and IEEE Computer Society, 2015, pp. 3128–3137

[15]

Fang, X.; Pan, R.; Cao, G.; He, X.; and Dai, W. 2015. Personalized tag recommendation through nonlinear tensor factorization using gaussian kernel. In AAAI, 439–445.

[16]

Feng, W., and Wang, J. 2012. Incorporating heterogeneous
information for personalized tag recommendation in social
tagging systems. In SIGKDD, 1276–1284. ACM.

[17]

Gong, Y., and Zhang, Q. 2016. Hashtag recommendation using attention-based convolutional neural network. In IJCAI,
2782–2788.

[18]

Gong, Y.; Jia, Y.; Leung, T.; Toshev, A.; and Ioffe, S. 2013.
Deep convolutional ranking for multilabel image annotation.
arXiv.

[19]

Gong, Y.; Ke, Q.; Isard, M.; and Lazebnik, S. 2014. A
multi-view embedding space for modeling internet images,
tags, and their semantics. IJCV 106(2):210–233.

[20]

Guan, Z.; Bu, J.; Mei, Q.; Chen, C.; and Wang, C. 2009.
Personalized tag recommendation using graph-based ranking on multi-type interrelated objects. In SIGIR, 540–547.
ACM.

[21]

Hasan, M.; Agu, E.; and Rundensteiner, E. 2014. Using
hashtags as labels for supervised learning of emotions in
twitter messages. In ACM SIGKDD Workshop on Health
Informatics.

[22]

Highfield, T., and Leaver, T. 2015. A methodology for mapping instagram hashtags. First Monday 20(1):1–11.

[23]

Huang, H.; Zhang, Q.; Gong, Y.; and Huang, X. 2016. Hashtag recommendation using end-to-end memory networks
with hierarchical attention. In COLING, 943–952.

[24]

Hwang, S. J., and Grauman, K. 2012. Learning the relative importance of objects from tagged images for retrieval
and cross-modal search. International journal of computer
vision 100(2):134–153.

[25]

Krestel, R.; Fankhauser, P.; and Nejdl, W. 2009. Latent
dirichlet allocation for tag recommendation. In RecSys, 61–
68.


[26]


Li, Y.; Liu, T.; Jiang, J.; and Zhang, L. 2016. Hashtag recommendation with topical attention-based lstm. In COLING,
3019–3029.

[27]

Lim, K. W., and Buntine, W. 2014. Twitter opinion topic
model: Extracting product opinions from tweets by leveraging hashtags and sentiment lexicon. In CIKM, 1319–1328.

[28]

Liu, D.; Hua, X.-S.; Yang, L.; Wang, M.; and Zhang, H.-J.
2009. Tag ranking. In WWW, 351–360. ACM.

\end{multicols}

\end{document}
